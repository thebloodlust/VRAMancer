# setup.cfg
[metadata]
name = vramancer
version = 0.2.0
description = GPU‑aware inference framework for GPT‑2‑style models
author = Your Name
author_email = you@example.com
url = https://github.com/your‑org/vrc_inference
license = MIT
classifiers =
    Development Status :: 4 - Beta
    Programming Language :: Python :: 3
    License :: OSI Approved :: MIT License
    Intended Audience :: Developers
    Topic :: Scientific/Engineering :: Artificial Intelligence

[options]
python_requires = >=3.9
install_requires =
    torch==2.2.0
    numpy==1.26.0
    pyyaml==6.0.1
    psutil==5.9.8
    transformers==4.34.0
    accelerate==0.27.2
    flask==3.0.2
    python-socketio==5.11.1
    nvidia-ml-py==11.525.112
    pycryptodome==3.20.0
    prometheus-client==0.21.0
    rich==13.9.4

[options.extras_require]
gui =
    PyQt5==5.15.9
    dash==2.15.0
    plotly==5.22.0
vision =
    torchvision==0.17.0
compression =
    lz4==4.3.3
    zstandard==0.22.0
tracing =
    opentelemetry-api==1.25.0
    opentelemetry-sdk==1.25.0
    opentelemetry-exporter-otlp==1.25.0
test =
    pytest
    pytest-cov
    flake8
dev =
    pip-tools
    mypy
    black
    isort
server =
    lz4==4.3.3
    zstandard==0.22.0
    opentelemetry-api==1.25.0
    opentelemetry-sdk==1.25.0
    opentelemetry-exporter-otlp==1.25.0
lite =
    # minimal CLI runtime (no GUI, vision, tracing)
all =
    PyQt5==5.15.9
    dash==2.15.0
    plotly==5.22.0
    torchvision==0.17.0
    lz4==4.3.3
    zstandard==0.22.0
    opentelemetry-api==1.25.0
    opentelemetry-sdk==1.25.0
    opentelemetry-exporter-otlp==1.25.0
    pip-tools
    mypy
    black
    isort

[options.entry_points]
console_scripts =
    vramancer = vramancer.main:main
    vramancer-health = core.health:main
