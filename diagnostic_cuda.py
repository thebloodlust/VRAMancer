#!/usr/bin/env python3
"""Diagnostic CUDA/GPU complet pour RTX 4060 Ti."""

import sys
import os
import subprocess

def run_command(cmd, description):
    """Execute une commande et affiche le r√©sultat."""
    print(f"\nüîç {description}")
    print("=" * 50)
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, shell=True)
        if result.stdout:
            print(result.stdout.strip())
        if result.stderr:
            print(f"STDERR: {result.stderr.strip()}")
        if result.returncode != 0:
            print(f"Code retour: {result.returncode}")
    except Exception as e:
        print(f"Erreur: {e}")

def main():
    print("=" * 60)
    print("    DIAGNOSTIC CUDA/GPU - RTX 4060 Ti")
    print("=" * 60)
    
    # 1. Infos syst√®me de base
    print(f"\nüìä SYST√àME:")
    print(f"Python: {sys.version}")
    print(f"Plateforme: {sys.platform}")
    print(f"Architecture: {os.name}")
    
    # 2. Variables d'environnement CUDA
    print(f"\nüîß VARIABLES ENVIRONNEMENT CUDA:")
    cuda_vars = ['CUDA_PATH', 'CUDA_HOME', 'CUDA_ROOT', 'PATH']
    for var in cuda_vars:
        value = os.environ.get(var, 'Non d√©fini')
        print(f"{var}: {value}")
    
    # 3. Commandes syst√®me pour NVIDIA
    commands = [
        ('nvidia-smi', 'NVIDIA System Management Interface'),
        ('nvcc --version', 'NVIDIA CUDA Compiler'),
        ('wmic path win32_VideoController get name', 'Cartes graphiques Windows'),
        ('dxdiag /t dxdiag.txt && type dxdiag.txt', 'DirectX Diagnostic (partiel)'),
    ]
    
    for cmd, desc in commands:
        run_command(cmd, desc)
    
    # 4. Test PyTorch CUDA
    print(f"\nüî• TEST PYTORCH CUDA:")
    print("=" * 50)
    try:
        import torch
        print(f"PyTorch version: {torch.__version__}")
        print(f"CUDA disponible: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"Nombre GPUs: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"GPU {i}: {props.name}")
                print(f"  M√©moire: {props.total_memory / 1024**3:.1f} GB")
                print(f"  Compute capability: {props.major}.{props.minor}")
        else:
            print("‚ùå CUDA non disponible dans PyTorch")
            print("Causes possibles:")
            print("- PyTorch CPU-only install√©")
            print("- Drivers NVIDIA manquants")
            print("- CUDA Toolkit non install√©")
            print("- Version CUDA incompatible")
            
    except ImportError:
        print("‚ùå PyTorch non install√©")
    except Exception as e:
        print(f"‚ùå Erreur PyTorch: {e}")
    
    # 5. Test alternative avec core.utils
    print(f"\n‚öôÔ∏è TEST VRAMANCER CORE.UTILS:")
    print("=" * 50)
    try:
        sys.path.insert(0, os.getcwd())
        from core.utils import detect_backend, enumerate_devices
        
        backend = detect_backend()
        devices = enumerate_devices()
        
        print(f"Backend d√©tect√©: {backend}")
        print(f"Nombre devices: {len(devices)}")
        
        for device in devices:
            print(f"- {device['id']}: {device['name']} ({device['backend']})")
            if device.get('total_memory'):
                print(f"  M√©moire: {device['total_memory'] / 1024**3:.1f} GB")
                
    except Exception as e:
        print(f"‚ùå Erreur core.utils: {e}")
    
    # 6. Recommandations
    print(f"\nüí° RECOMMANDATIONS:")
    print("=" * 50)
    print("Pour RTX 4060 Ti + i5 12e gen:")
    print()
    print("1. DRIVERS NVIDIA:")
    print("   - Installez les derniers drivers GeForce")
    print("   - Red√©marrez apr√®s installation")
    print()
    print("2. CUDA TOOLKIT:")
    print("   - T√©l√©chargez CUDA 12.x depuis nvidia.com/cuda")
    print("   - Ajoutez au PATH : C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.x\\bin")
    print()
    print("3. PYTORCH CUDA:")
    print("   - D√©sinstallez : pip uninstall torch")
    print("   - R√©installez CUDA : pip install torch --index-url https://download.pytorch.org/whl/cu121")
    print()
    print("4. V√âRIFICATION:")
    print("   - Red√©marrez l'ordinateur")
    print("   - Relancez ce diagnostic")
    print("   - nvidia-smi doit afficher la RTX 4060 Ti")

if __name__ == "__main__":
    main()