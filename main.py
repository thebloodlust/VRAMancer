import torch
from core.model_splitter import ModelSplitter
from core.stream_manager import StreamManager
from core.compute_engine import ComputeEngine
from core.transfer_manager import TransferManager
from core.memory_balancer import MemoryBalancer
from core.scheduler import Scheduler
from core.logger import Logger

def main():
    print("ðŸš€ VRAMancer Deluxe California Ripper â€” Initialisation")

    # Initialisation des modules
    scheduler = Scheduler()
    logger = Logger()
    splitter = ModelSplitter("bert-base-uncased")
    streamer = StreamManager(scheduler, logger)
    engine = ComputeEngine(backend="auto")
    transfer = TransferManager(protocol="vramancer", secure=True)
    balancer = MemoryBalancer(scheduler, logger)

    # DÃ©tection des GPUs
    gpus = scheduler.get_available_gpus()
    print(f"ðŸ§  GPUs dÃ©tectÃ©s : {[gpu['id'] for gpu in gpus]}")

    # DÃ©coupage du modÃ¨le
    allocation = splitter.split_by_gpu(gpus)
    print("ðŸ“¦ RÃ©partition des couches :")
    for gpu_id, layers in allocation.items():
        print(f"  GPU {gpu_id} â†’ {len(layers)} couches")

    # Simulation dâ€™un batch dâ€™entrÃ©e
    batch = torch.randn(32, 768)

    # Historique fictif pour prÃ©diction
    usage_history = {gpu["id"]: [random.randint(60, 95) for _ in range(5)] for gpu in gpus}

    # Boucle dâ€™exÃ©cution
    for gpu_id, layers in allocation.items():
        print(f"\nðŸŽ¯ Traitement sur GPU {gpu_id}")
        streamer.prefetch_layers(layers, lookahead=3)

        for layer in layers:
            # Chargement
            block = streamer.preload_layer(layer)

            # ExÃ©cution
            output = engine.execute_layer(layer, batch, device_id=gpu_id, track_gradients=True, use_compile=True, profile_gpu=True)

            # Synchronisation
            activations_map = {layer["name"]: (gpu_id, (gpu_id + 1) % len(gpus), output)}
            transfer.sync_activations(activations_map)

            # RÃ©Ã©quilibrage mÃ©moire
            balancer.balance([layer])
            balancer.predictive_balance(usage_history)

            # LibÃ©ration
            streamer.release_layer(layer["name"])

        # Monitoring live
        streamer.live_monitoring()
        balancer.emergency_release()

    print("\nâœ… ExÃ©cution terminÃ©e â€” VRAMancer Deluxe a tout donnÃ© ðŸ’¥")

if __name__ == "__main__":
    main()
