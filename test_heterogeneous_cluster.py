#!/usr/bin/env python3
"""
Script de test et configuration pour le cluster h√©t√©rog√®ne de l'utilisateur
Configuration sp√©cifique: EPYC + RTX3090 + MI50 + laptop i5 4060Ti + MacBook M4
"""

import os
import sys
import json
import platform
import subprocess
from pathlib import Path

class HeterogeneousClusterTester:
    def __init__(self):
        self.cluster_config = {
            "master_node": {
                "type": "server",
                "hardware": "EPYC 7xx3 + RTX 3090 + AMD MI50",
                "ram": "256GB",
                "os": "Ubuntu (Proxmox)",
                "role": "master",
                "backends": ["cuda", "rocm", "cpu"],
                "ip": "192.168.1.100",  # √Ä adapter
                "priority": 1
            },
            "laptop_node": {
                "type": "laptop", 
                "hardware": "i5-12xxx + RTX 4060Ti",
                "ram": "16-32GB",
                "os": "Windows 11",
                "role": "worker",
                "backends": ["cuda", "cpu"],
                "ip": "192.168.1.101",  # √Ä adapter
                "priority": 2
            },
            "macbook_node": {
                "type": "edge",
                "hardware": "Apple M4",
                "ram": "32GB+",
                "os": "macOS",
                "role": "edge",
                "backends": ["mps", "cpu"],
                "ip": "192.168.1.102",  # √Ä adapter  
                "priority": 3
            }
        }
        
        self.current_node = self.detect_current_node()
    
    def detect_current_node(self):
        """D√©tecte automatiquement le n≈ìud actuel"""
        system = platform.system()
        processor = platform.processor()
        
        if system == "Windows":
            return "laptop_node"
        elif system == "Darwin":  # macOS
            return "macbook_node" 
        elif system == "Linux":
            return "master_node"
        else:
            return "unknown"
    
    def test_gpu_backends(self):
        """Teste les backends GPU disponibles sur ce n≈ìud"""
        print(f"üîç Test des backends GPU sur {self.current_node}...")
        
        backends_found = []
        
        # Test CUDA
        try:
            import torch
            if torch.cuda.is_available():
                backends_found.append("cuda")
                print(f"‚úÖ CUDA disponible: {torch.cuda.get_device_name()}")
                print(f"   - Devices: {torch.cuda.device_count()}")
                print(f"   - Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3}GB")
        except Exception as e:
            print(f"‚ùå CUDA non disponible: {e}")
        
        # Test ROCm (AMD)
        try:
            if hasattr(torch, 'version') and hasattr(torch.version, 'hip'):
                backends_found.append("rocm")
                print("‚úÖ ROCm disponible")
        except:
            pass
        
        # Test Apple MPS
        try:
            import torch
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                backends_found.append("mps")
                print("‚úÖ Apple MPS disponible")
        except:
            pass
        
        # CPU toujours disponible
        backends_found.append("cpu")
        print("‚úÖ CPU backend disponible")
        
        return backends_found
    
    def generate_node_config(self):
        """G√©n√®re la configuration pour ce n≈ìud"""
        node_info = self.cluster_config.get(self.current_node, {})
        backends = self.test_gpu_backends()
        
        config = {
            "node_id": self.current_node,
            "node_type": node_info.get("type", "unknown"),
            "role": node_info.get("role", "worker"),
            "backends": backends,
            "capabilities": {
                "compute_score": self.calculate_compute_score(backends),
                "memory_score": self.calculate_memory_score(),
                "network_score": 80  # Par d√©faut
            },
            "cluster": {
                "master_ip": self.cluster_config["master_node"]["ip"],
                "discovery_port": 8899,
                "api_port": 5030
            }
        }
        
        return config
    
    def calculate_compute_score(self, backends):
        """Calcule le score de calcul selon les backends"""
        scores = {
            "cuda": 90,  # RTX 3090/4060Ti
            "rocm": 85,  # MI50  
            "mps": 75,   # Apple M4
            "cpu": 30    # Fallback CPU
        }
        
        return max([scores.get(b, 0) for b in backends])
    
    def calculate_memory_score(self):
        """Calcule le score m√©moire"""
        try:
            import psutil
            total_ram = psutil.virtual_memory().total // (1024**3)
            
            if total_ram >= 200:  # EPYC 256GB
                return 100
            elif total_ram >= 30:  # MacBook/Laptop 32GB
                return 70
            elif total_ram >= 15:  # Laptop 16GB
                return 50
            else:
                return 30
        except:
            return 50
    
    def setup_cluster_node(self):
        """Configure ce n≈ìud pour le cluster"""
        print(f"‚öôÔ∏è Configuration du n≈ìud {self.current_node}...")
        
        config = self.generate_node_config()
        
        # Sauvegarder la config
        os.makedirs("config", exist_ok=True)
        with open(f"config/node_{self.current_node}.json", "w") as f:
            json.dump(config, f, indent=2)
        
        print(f"‚úÖ Configuration sauv√©e: config/node_{self.current_node}.json")
        
        # Cr√©er le script de lancement pour ce n≈ìud
        self.create_node_launcher(config)
        
        return config
    
    def create_node_launcher(self, config):
        """Cr√©e un script de lancement sp√©cifique au n≈ìud"""
        role = config["role"]
        
        if role == "master":
            script_content = f'''#!/bin/bash
# Lanceur n≈ìud ma√Ætre EPYC
echo "üöÄ D√©marrage n≈ìud ma√Ætre EPYC..."

# Variables d'environnement
export CUDA_VISIBLE_DEVICES=0,1  # RTX3090 + MI50
export VRM_NODE_ROLE=master
export VRM_API_PORT=5030

# Lancer l'orchestrateur h√©t√©rog√®ne
python core/orchestrator/heterogeneous_manager.py --role master &

# Lancer l'API unifi√©e
python -m core.api.unified_api &

# Lancer le dashboard web
python dashboard/dashboard_web.py &

# Lancer le monitoring mobile
python mobile/dashboard_heterogeneous.py &

echo "‚úÖ N≈ìud ma√Ætre d√©marr√©"
echo "   - API: http://localhost:5030"
echo "   - Dashboard: http://localhost:5000"  
echo "   - Mobile: http://localhost:8080"

wait
'''
        
        elif role == "worker":
            master_ip = config["cluster"]["master_ip"]
            script_content = f'''@echo off
title VRAMancer Worker Node - Laptop i5 4060Ti
echo üöÄ Demarrage noeud worker laptop...

REM Variables d'environnement Windows
set CUDA_VISIBLE_DEVICES=0
set VRM_NODE_ROLE=worker
set VRM_MASTER_IP={master_ip}

REM Lancer le worker
python core/orchestrator/heterogeneous_manager.py --role worker --master-ip {master_ip}

echo ‚úÖ Noeud worker demarre et connecte au maitre
pause
'''
        
        elif role == "edge":
            master_ip = config["cluster"]["master_ip"]
            script_content = f'''#!/bin/bash
# Lanceur n≈ìud edge MacBook M4
echo "üöÄ D√©marrage n≈ìud edge MacBook M4..."

# Variables d'environnement macOS
export VRM_NODE_ROLE=edge
export VRM_MASTER_IP={master_ip}
export VRM_BACKEND=mps

# Lancer le n≈ìud edge
python core/orchestrator/heterogeneous_manager.py --role edge --master-ip {master_ip} --backend mps

echo "‚úÖ N≈ìud edge MacBook connect√© au cluster"
'''
        
        # Sauvegarder le script
        if role == "master":
            filename = "start_master_node.sh"
        elif role == "worker":
            filename = "start_worker_node.bat"
        else:  # edge
            filename = "start_edge_node.sh"
        
        with open(filename, "w") as f:
            f.write(script_content)
        
        # Rendre ex√©cutable sur Unix
        if filename.endswith(".sh"):
            os.chmod(filename, 0o755)
        
        print(f"‚úÖ Script de lancement cr√©√©: {filename}")
    
    def test_cluster_connectivity(self):
        """Teste la connectivit√© du cluster"""
        print("üåê Test de connectivit√© cluster...")
        
        master_ip = self.cluster_config["master_node"]["ip"]
        
        # Test ping
        try:
            if platform.system() == "Windows":
                result = subprocess.run(["ping", "-n", "1", master_ip], 
                                      capture_output=True, text=True)
            else:
                result = subprocess.run(["ping", "-c", "1", master_ip], 
                                      capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"‚úÖ Connectivit√© r√©seau OK vers {master_ip}")
            else:
                print(f"‚ùå Pas de connectivit√© vers {master_ip}")
                print("üí° V√©rifiez l'IP du n≈ìud ma√Ætre dans la config")
        except Exception as e:
            print(f"‚ö†Ô∏è Test ping impossible: {e}")
        
        # Test ports API
        try:
            import socket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(3)
            result = sock.connect_ex((master_ip, 5030))
            sock.close()
            
            if result == 0:
                print(f"‚úÖ API ma√Ætre accessible sur {master_ip}:5030")
            else:
                print(f"‚ùå API ma√Ætre inaccessible sur {master_ip}:5030")
        except Exception as e:
            print(f"‚ö†Ô∏è Test API impossible: {e}")
    
    def show_cluster_status(self):
        """Affiche l'√©tat du cluster"""
        print("\n" + "="*60)
        print("üèÅ Configuration Cluster H√©t√©rog√®ne VRAMancer")
        print("="*60)
        
        for node_name, node_info in self.cluster_config.items():
            status = "üü¢ ACTUEL" if node_name == self.current_node else "‚ö™ AUTRE"
            print(f"\n{status} {node_info['type'].upper()} ({node_name}):")
            print(f"   Hardware: {node_info['hardware']}")
            print(f"   RAM: {node_info['ram']}")
            print(f"   OS: {node_info['os']}")
            print(f"   Role: {node_info['role']}")
            print(f"   Backends: {', '.join(node_info['backends'])}")
            print(f"   IP: {node_info['ip']}")
        
        print(f"\nüéØ Architecture:")
        print(f"   - N≈ìud Ma√Ætre: EPYC (orchestration + calcul lourd)")
        print(f"   - N≈ìud Worker: Laptop (calcul interm√©diaire)")  
        print(f"   - N≈ìud Edge: MacBook (t√¢ches l√©g√®res + mobile)")
        
        print(f"\nüîÑ Auto-sensing des performances:")
        print(f"   - D√©tection automatique CUDA/ROCm/MPS")
        print(f"   - √âquilibrage selon compute/memory scores")
        print(f"   - Failover automatique ma√Ætre-esclave")
    
    def run_full_test(self):
        """Lance tous les tests"""
        print("üß™ Test complet du cluster h√©t√©rog√®ne VRAMancer")
        print("="*60)
        
        # 1. D√©tection du n≈ìud
        print(f"\n1Ô∏è‚É£ N≈ìud d√©tect√©: {self.current_node}")
        
        # 2. Test des backends
        print(f"\n2Ô∏è‚É£ Test des backends GPU:")
        backends = self.test_gpu_backends()
        
        # 3. Configuration du n≈ìud
        print(f"\n3Ô∏è‚É£ Configuration du n≈ìud:")
        config = self.setup_cluster_node()
        
        # 4. Test connectivit√©
        print(f"\n4Ô∏è‚É£ Test connectivit√©:")
        self.test_cluster_connectivity()
        
        # 5. Statut cluster
        print(f"\n5Ô∏è‚É£ Statut du cluster:")
        self.show_cluster_status()
        
        # 6. Prochaines √©tapes
        print(f"\n6Ô∏è‚É£ Prochaines √©tapes:")
        
        if self.current_node == "master_node":
            print("   - Lancez: ./start_master_node.sh")
            print("   - Dashboard: http://localhost:5000")
            print("   - Mobile: http://localhost:8080")
        
        elif self.current_node == "laptop_node":
            print("   - Lancez: start_worker_node.bat")
            print("   - V√©rifiez la connexion au ma√Ætre")
        
        elif self.current_node == "macbook_node":
            print("   - Lancez: ./start_edge_node.sh")
            print("   - Backend MPS sera utilis√©")
        
        print(f"\nüí° Astuce: Configuration sauv√©e dans config/node_{self.current_node}.json")

def main():
    """Point d'entr√©e principal"""
    tester = HeterogeneousClusterTester()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--backends-only":
            tester.test_gpu_backends()
        elif sys.argv[1] == "--config-only":
            tester.setup_cluster_node()
        elif sys.argv[1] == "--status":
            tester.show_cluster_status()
        else:
            print("Options: --backends-only, --config-only, --status")
    else:
        tester.run_full_test()

if __name__ == "__main__":
    main()