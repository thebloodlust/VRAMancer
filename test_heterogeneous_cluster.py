#!/usr/bin/env python3
"""
Script de test et configuration pour le cluster hÃ©tÃ©rogÃ¨ne de l'utilisateur
Configuration spÃ©cifique: EPYC + RTX3090 + MI50 + laptop i5 4060Ti + MacBook M4
"""

import os
import sys
import json
import platform
import subprocess
from pathlib import Path

class HeterogeneousClusterTester:
    def __init__(self):
        self.cluster_config = {
            "master_node": {
                "type": "server",
                "hardware": "EPYC 7xx3 + RTX 3090 + AMD MI50",
                "ram": "256GB",
                "os": "Ubuntu (Proxmox)",
                "role": "master",
                "backends": ["cuda", "rocm", "cpu"],
                "ip": "192.168.1.100",  # Ã€ adapter
                "priority": 1
            },
            "laptop_node": {
                "type": "laptop", 
                "hardware": "i5-12xxx + RTX 4060Ti",
                "ram": "16-32GB",
                "os": "Windows 11",
                "role": "worker",
                "backends": ["cuda", "cpu"],
                "ip": "192.168.1.101",  # Ã€ adapter
                "priority": 2
            },
            "macbook_node": {
                "type": "edge",
                "hardware": "Apple M4",
                "ram": "32GB+",
                "os": "macOS",
                "role": "edge",
                "backends": ["mps", "cpu"],
                "ip": "192.168.1.102",  # Ã€ adapter  
                "priority": 3
            }
        }
        
        self.current_node = self.detect_current_node()
    
    def detect_current_node(self):
        """DÃ©tecte automatiquement le nÅ“ud actuel"""
        system = platform.system()
        processor = platform.processor()
        
        if system == "Windows":
            return "laptop_node"
        elif system == "Darwin":  # macOS
            return "macbook_node" 
        elif system == "Linux":
            return "master_node"
        else:
            return "unknown"
    
    def test_gpu_backends(self):
        """Teste les backends GPU disponibles sur ce nÅ“ud"""
        print(f"ðŸ” Test des backends GPU sur {self.current_node}...")
        
        backends_found = []
        
        # Test CUDA
        try:
            import torch
            if torch.cuda.is_available():
                backends_found.append("cuda")
                print(f"âœ… CUDA disponible: {torch.cuda.get_device_name()}")
                print(f"   - Devices: {torch.cuda.device_count()}")
                print(f"   - Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3}GB")
        except Exception as e:
            print(f"âŒ CUDA non disponible: {e}")
        
        # Test ROCm (AMD)
        try:
            if hasattr(torch, 'version') and hasattr(torch.version, 'hip'):
                backends_found.append("rocm")
                print("âœ… ROCm disponible")
        except:
            pass
        
        # Test Apple MPS
        try:
            import torch
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                backends_found.append("mps")
                print("âœ… Apple MPS disponible")
        except:
            pass
        
        # CPU toujours disponible
        backends_found.append("cpu")
        print("âœ… CPU backend disponible")
        
        return backends_found
    
    def generate_node_config(self):
        """GÃ©nÃ¨re la configuration pour ce nÅ“ud"""
        node_info = self.cluster_config.get(self.current_node, {})
        backends = self.test_gpu_backends()
        
        config = {
            "node_id": self.current_node,
            "node_type": node_info.get("type", "unknown"),
            "role": node_info.get("role", "worker"),
            "backends": backends,
            "capabilities": {
                "compute_score": self.calculate_compute_score(backends),
                "memory_score": self.calculate_memory_score(),
                "network_score": 80  # Par dÃ©faut
            },
            "cluster": {
                "master_ip": self.cluster_config["master_node"]["ip"],
                "discovery_port": 8899,
                "api_port": 5030
            }
        }
        
        return config
    
    def calculate_compute_score(self, backends):
        """Calcule le score de calcul selon les backends"""
        scores = {
            "cuda": 90,  # RTX 3090/4060Ti
            "rocm": 85,  # MI50  
            "mps": 75,   # Apple M4
            "cpu": 30    # Fallback CPU
        }
        
        return max([scores.get(b, 0) for b in backends])
    
    def calculate_memory_score(self):
        """Calcule le score mÃ©moire"""
        try:
            import psutil
            total_ram = psutil.virtual_memory().total // (1024**3)
            
            if total_ram >= 200:  # EPYC 256GB
                return 100
            elif total_ram >= 30:  # MacBook/Laptop 32GB
                return 70
            elif total_ram >= 15:  # Laptop 16GB
                return 50
            else:
                return 30
        except:
            return 50
    
    def setup_cluster_node(self):
        """Configure ce nÅ“ud pour le cluster"""
        print(f"âš™ï¸ Configuration du nÅ“ud {self.current_node}...")
        
        config = self.generate_node_config()
        
        # Sauvegarder la config
        os.makedirs("config", exist_ok=True)
        with open(f"config/node_{self.current_node}.json", "w") as f:
            json.dump(config, f, indent=2)
        
        print(f"âœ… Configuration sauvÃ©e: config/node_{self.current_node}.json")
        
        # CrÃ©er le script de lancement pour ce nÅ“ud
        self.create_node_launcher(config)
        
        return config
    
    def create_node_launcher(self, config):
        """CrÃ©e un script de lancement spÃ©cifique au nÅ“ud"""
        role = config["role"]
        
        if role == "master":
            script_content = f'''#!/bin/bash
# Lanceur nÅ“ud maÃ®tre EPYC
echo "ðŸš€ DÃ©marrage nÅ“ud maÃ®tre EPYC..."

# Variables d'environnement
export CUDA_VISIBLE_DEVICES=0,1  # RTX3090 + MI50
export VRM_NODE_ROLE=master
export VRM_API_PORT=5030

# Lancer l'orchestrateur hÃ©tÃ©rogÃ¨ne
python core/orchestrator/heterogeneous_manager.py --role master &

# Lancer l'API unifiÃ©e
python -m core.api.unified_api &

# Lancer le dashboard web
python dashboard/dashboard_web.py &

# Lancer le monitoring mobile
python mobile/dashboard_heterogeneous.py &

echo "âœ… NÅ“ud maÃ®tre dÃ©marrÃ©"
echo "   - API: http://localhost:5030"
echo "   - Dashboard: http://localhost:5000"  
echo "   - Mobile: http://localhost:8080"

wait
'''
        
        elif role == "worker":
            master_ip = config["cluster"]["master_ip"]
            script_content = f'''@echo off
title VRAMancer Worker Node - Laptop i5 4060Ti
echo ðŸš€ Demarrage noeud worker laptop...

REM Variables d'environnement Windows
set CUDA_VISIBLE_DEVICES=0
set VRM_NODE_ROLE=worker
set VRM_MASTER_IP={master_ip}

REM Lancer le worker
python core/orchestrator/heterogeneous_manager.py --role worker --master-ip {master_ip}

echo âœ… Noeud worker demarre et connecte au maitre
pause
'''
        
        elif role == "edge":
            master_ip = config["cluster"]["master_ip"]
            script_content = f'''#!/bin/bash
# Lanceur nÅ“ud edge MacBook M4
echo "ðŸš€ DÃ©marrage nÅ“ud edge MacBook M4..."

# Variables d'environnement macOS
export VRM_NODE_ROLE=edge
export VRM_MASTER_IP={master_ip}
export VRM_BACKEND=mps

# Lancer le nÅ“ud edge
python core/orchestrator/heterogeneous_manager.py --role edge --master-ip {master_ip} --backend mps

echo "âœ… NÅ“ud edge MacBook connectÃ© au cluster"
'''
        
        # Sauvegarder le script
        if role == "master":
            filename = "start_master_node.sh"
        elif role == "worker":
            filename = "start_worker_node.bat"
        else:  # edge
            filename = "start_edge_node.sh"
        
        with open(filename, "w") as f:
            f.write(script_content)
        
        # Rendre exÃ©cutable sur Unix
        if filename.endswith(".sh"):
            os.chmod(filename, 0o755)
        
        print(f"âœ… Script de lancement crÃ©Ã©: {filename}")
    
    def test_cluster_connectivity(self):
        """Teste la connectivitÃ© du cluster"""
        print("ðŸŒ Test de connectivitÃ© cluster...")
        
        master_ip = self.cluster_config["master_node"]["ip"]
        
        # Test ping
        try:
            if platform.system() == "Windows":
                result = subprocess.run(["ping", "-n", "1", master_ip], 
                                      capture_output=True, text=True)
            else:
                result = subprocess.run(["ping", "-c", "1", master_ip], 
                                      capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"âœ… ConnectivitÃ© rÃ©seau OK vers {master_ip}")
            else:
                print(f"âŒ Pas de connectivitÃ© vers {master_ip}")
                print("ðŸ’¡ VÃ©rifiez l'IP du nÅ“ud maÃ®tre dans la config")
        except Exception as e:
            print(f"âš ï¸ Test ping impossible: {e}")
        
        # Test ports API
        try:
            import socket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(3)
            result = sock.connect_ex((master_ip, 5030))
            sock.close()
            
            if result == 0:
                print(f"âœ… API maÃ®tre accessible sur {master_ip}:5030")
            else:
                print(f"âŒ API maÃ®tre inaccessible sur {master_ip}:5030")
        except Exception as e:
            print(f"âš ï¸ Test API impossible: {e}")
    
    def show_cluster_status(self):
        """Affiche l'Ã©tat du cluster"""
        print("\n" + "="*60)
        print("ðŸ Configuration Cluster HÃ©tÃ©rogÃ¨ne VRAMancer")
        print("="*60)
        
        for node_name, node_info in self.cluster_config.items():
            status = "ðŸŸ¢ ACTUEL" if node_name == self.current_node else "âšª AUTRE"
            print(f"\n{status} {node_info['type'].upper()} ({node_name}):")
            print(f"   Hardware: {node_info['hardware']}")
            print(f"   RAM: {node_info['ram']}")
            print(f"   OS: {node_info['os']}")
            print(f"   Role: {node_info['role']}")
            print(f"   Backends: {', '.join(node_info['backends'])}")
            print(f"   IP: {node_info['ip']}")
        
        print(f"\nðŸŽ¯ Architecture:")
        print(f"   - NÅ“ud MaÃ®tre: EPYC (orchestration + calcul lourd)")
        print(f"   - NÅ“ud Worker: Laptop (calcul intermÃ©diaire)")  
        print(f"   - NÅ“ud Edge: MacBook (tÃ¢ches lÃ©gÃ¨res + mobile)")
        
        print(f"\nðŸ”„ Auto-sensing des performances:")
        print(f"   - DÃ©tection automatique CUDA/ROCm/MPS")
        print(f"   - Ã‰quilibrage selon compute/memory scores")
        print(f"   - Failover automatique maÃ®tre-esclave")
    
    def run_full_test(self):
        """Lance tous les tests"""
        print("ðŸ§ª Test complet du cluster hÃ©tÃ©rogÃ¨ne VRAMancer")
        print("="*60)
        
        # 1. DÃ©tection du nÅ“ud
        print(f"\n1ï¸âƒ£ NÅ“ud dÃ©tectÃ©: {self.current_node}")
        
        # 2. Test des backends
        print(f"\n2ï¸âƒ£ Test des backends GPU:")
        backends = self.test_gpu_backends()
        
        # 3. Configuration du nÅ“ud
        print(f"\n3ï¸âƒ£ Configuration du nÅ“ud:")
        config = self.setup_cluster_node()
        
        # 4. Test connectivitÃ©
        print(f"\n4ï¸âƒ£ Test connectivitÃ©:")
        self.test_cluster_connectivity()
        
        # 5. Statut cluster
        print(f"\n5ï¸âƒ£ Statut du cluster:")
        self.show_cluster_status()
        
        # 6. Prochaines Ã©tapes
        print(f"\n6ï¸âƒ£ Prochaines Ã©tapes:")
        
        if self.current_node == "master_node":
            print("   - Lancez: ./start_master_node.sh")
            print("   - Dashboard: http://localhost:5000")
            print("   - Mobile: http://localhost:8080")
        
        elif self.current_node == "laptop_node":
            print("   - Lancez: start_worker_node.bat")
            print("   - VÃ©rifiez la connexion au maÃ®tre")
        
        elif self.current_node == "macbook_node":
            print("   - Lancez: ./start_edge_node.sh")
            print("   - Backend MPS sera utilisÃ©")
        
        print(f"\nðŸ’¡ Astuce: Configuration sauvÃ©e dans config/node_{self.current_node}.json")

def main():
    """Point d'entrÃ©e principal"""
    tester = HeterogeneousClusterTester()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--backends-only":
            tester.test_gpu_backends()
        elif sys.argv[1] == "--config-only":
            tester.setup_cluster_node()
        elif sys.argv[1] == "--status":
            tester.show_cluster_status()
        else:
            print("Options: --backends-only, --config-only, --status")
    else:
        tester.run_full_test()

if __name__ == "__main__":
    main()